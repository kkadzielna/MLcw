{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read in the fashion dataset\n",
    "2. read (maybe make notes?)about PCA\n",
    "3. implement 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 PCA\n",
    "#### Run PCA on the fashion-MNIST dataset.\n",
    "1. How much variance do the first and second principal components explain? (5 marks)\n",
    "2. Create a 2D scatterplot of the data projected onto the first two principal components. Differentiate between the different classes using colour. To what extent do the datapoints in your scatter plot cluster into the different classes? (5 marks)\n",
    "\n",
    "#### PCA implementation\n",
    "PCA consists of two main steps:\n",
    "1. Find a new set of basis vectors, named the principal components, according to how much of the variance within the dataset each of these components are able to capture. The first principal component corresponds to the one which captures the most variance, the second principal component corresponds to the second most variance and so on.\n",
    "2. Select the first $n$ principal components and project the original data to this new basis.\n",
    "\n",
    "In particular, the principal components correspond to the eigenvectors of the covariance matrix of the data. The corresponding eigenvalues capture the amount of variance in that direction.\n",
    "\n",
    "The new space is given by projecting the data onto the eigenvectors of the covariance matrix:\n",
    "$$ S = XU$$\n",
    "where $X$ is the $N \\times D$ matrix containing the original data, $S$ is an $N \\times D$ matrix representing the projected data (also called scores), and $U$ is an $D \\times D$ orthonormal matrix where each of the columns represent an eigenvector of the covariance matrix.\n",
    "\n",
    "##### Eigenvectors\n",
    "Computing eigenvectors is critical for performing PCA. Given a dataset `X` and a covariance matrix ```cov_matrix```, your task is to:\n",
    "1. Find the eigenvalues and eigenvector of the covariance matrix. (hint: ```np.linalg.eigh()```)\n",
    "2. Sort the eigenvalues in descending order. (use the provided function ```sort_evals_descending()```)\n",
    "3. Plot both the data and the new eigenvectors. (use the provided function ```plot_basis_vectors()```)\n",
    "\n",
    "##### PCA\n",
    "Next, create a function ```pca(X)``` to perform PCA with given data input `X`. The main steps you need to implement are:\n",
    "1. Obtain the covariance matrix $S$ from `X` (where $\\bar{x}$ is the mean):\n",
    "$$ S = \\frac{1}{N} \\sum_{n=1}^N (x_n- \\bar{x})(x_n- \\bar{x})^T $$\n",
    "2. Find the eigenvalues, eigenvectors and sort them (as you did in the previous exercise)\n",
    "3. Project the initial data, `X`, onto the newly obtained eigenvectors  (hint: ```np.matmul()```)\n",
    "4. The function should return 3 parameters:\n",
    "    * `score`: the data projected onto the new basis\n",
    "    * `evectors`: eigenvectors\n",
    "    * `evals`: corresponding eigenvalues\n",
    "    \n",
    "Finally plot the score by utilising the provided function ```plot_data_new_basis(Y)``` where the input Y is the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much variance do the first and second principal components explain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(name='Fashion-MNIST')\n",
    "X = np.array(mnist.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2905654  0.17738509]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D scatterplot of the data projected onto the first two principal components. Differentiate between the different classes using colour. To what extent do the datapoints in your scatter plot cluster into the different classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
